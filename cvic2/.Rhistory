theme_minimal() +
scale_fill_identity()
ggplot(data_letters, aes(x = name, y = values, fill = "skyblue")) +
geom_bar(stat = "identity", color = "black") +  # Přidáme černý obrys pro lepší vizualitu
labs(title = "Sloupcový graf s chybovými úsečkami", x = "Jméno", y = "Hodnota") +
theme_minimal() +
scale_fill_identity()
ggplot(data, aes(x = name, y = values)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black") +  # Sloupcový graf
geom_errorbar(aes(ymin = values - sd, ymax = values + sd), width = .2, color = "orange") +  # Chybové úsečky
labs(title = "Sloupcový graf s chybovými úsečkami", x = "Jméno", y = "Hodnota") +
theme_minimal()
ggplot(data_letters, aes(x = name, y = values)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black") +  # Sloupcový graf
geom_errorbar(aes(ymin = values - sd, ymax = values + sd), width = .2, color = "orange") +  # Chybové úsečky
labs(title = "Sloupcový graf s chybovými úsečkami", x = "Jméno", y = "Hodnota") +
theme_minimal()
library(readr)
adult <- read_csv("D:/Skola/semester8/anal_roz_viceroz_dat/cvic2/adult.csv")
View(adult)
num_attributes <- ncol(data)
missing_values <- sum(is.na(data))
num_attributes
library(ggplot2)
ggplot(data, aes(x = workclass)) +
geom_histogram(stat = "count", fill = "skyblue") +
labs(title = "Histogram of Workclass", x = "Workclass", y = "Frequency")
ggplot(adult, aes(x = workclass)) +
geom_histogram(stat = "count", fill = "skyblue") +
labs(title = "Histogram of Workclass", x = "Workclass", y = "Frequency")
# Zjištění modu (nejčastější hodnoty) pro 'hours.per.week'
dominant_hours <- names(which.max(table(data$hours.per.week)))
dominant_hours
# Počet jedinečných tříd cílové proměnné
num_classes <- length(unique(data$income))
# Počet jedinečných tříd cílové proměnné
num_classes <- length(unique(data$income))
num_classes
# Zjištění modu (nejčastější hodnoty) pro 'hours.per.week'
dominant_hours <- workclass(which.max(table(data$hours.per.week)))
# Zjištění modu (nejčastější hodnoty) pro 'hours.per.week'
dominant_hours <- names(which.max(table(data$hours.per.week)))
# Počet jedinečných tříd cílové proměnné
num_classes <- length(unique(data$income))
# Zjištění modu (nejčastější hodnoty) pro 'hours.per.week'
dominant_hours <- names(which.max(table(data$hours.per.week)))
print(dominant_hours)
num_classes <- length(unique(data$income))
print(num_classes)
names(data)
num_attributes <- ncol(adult)
missing_values <- sum(is.na(adult))
library(ggplot2)
ggplot(adult, aes(x = workclass)) +
geom_histogram(stat = "count", fill = "skyblue") +
labs(title = "Histogram of Workclass", x = "Workclass", y = "Frequency")
num_attributes <- ncol(adult)
missing_values <- sum(is.na(adult))
library(readr)
adult <- read_csv("D:/Skola/semester8/anal_roz_viceroz_dat/cvic2/adult.csv")
View(adult)
num_attributes <- ncol(adult)
missing_values <- sum(is.na(adult))
View(adult)
View(adult)
missing_values <- sum(`is.na<-`?(adult))
missing_values <- sum(`is.na<-?`(adult))
missing_values <- sum(`is.na<-`?,(adult))
## Exercise 5
adult.na.string <- "?"
missing_values <- sum(is.na(adult))
## Exercise 5
# Předpokládáme, že data byla načtena takto
adult <- read.csv("adult.csv", header = TRUE, na.strings = "?")
getwd()
## Exercise 5
setwd("D:/Skola/semester8/anal_roz_viceroz_dat/cvic2")
adult <- read.csv("adult.csv", header = TRUE, na.strings = "?")
# Vypočet počtu chybějících hodnot v datasetu
missing_values <- sum(is.na(adult))
print(missing_values)
## Exercise 5
# ADULTS
str(adult)
summary(adult)
dim(adult)
barplot(table(adult$workclass))
sort(table(adult$`hours.per.week`))
table(adult$class)
## Exercise 5
data <- adult
cat("Počet atributů:", length(data))
# Kontrola chybějících hodnot
cat("Chybějící hodnoty v každém atributu:\n")
print(colSums(is.na(data)))
# Histogram pro atribut 'workclass'
ggplot(data, aes(x = workclass)) +
geom_bar(stat = "count", fill = "steelblue") +
theme_minimal() +
labs(title = "Histogram of Workclass", x = "Workclass", y = "Frequency")
# Zjištění, co znamená '?' v atributu 'workclass'
cat("Hodnota '?' v atributu 'workclass' označuje neznámé nebo chybějící údaje.\n")
# Zjištění, co znamená '?' v atributu 'workclass'
cat("Hodnota '?' v atributu 'workclass' označuje jinak pracující lidi nebo to nechtěli uvádět")
# Zjištění dominantní hodnoty u atributu 'hours.per.week'
dominant_value <- as.integer(names(which.max(table(data$hours.per.week))))
cat("Dominantní hodnota atributu 'hours.per.week' je:", dominant_value, "\n")
# Zjištění počtu tříd pro klasifikaci
cat("Počet tříd pro klasifikaci:", length(unique(data$class)), "\n")
library(readr)
snsdata <- read_csv("D:/Skola/semester8/anal_roz_viceroz_dat/cvic3/snsdata.csv")
View(snsdata)
View(snsdata)
View(snsdata)
## Exercise 1
summary(teens)
## Exercise 1
teens <- snsdata
summary(teens)
teens$missing_gender <- ifelse(is.na(teens$gender), 1, 0)
table(teens$gender)
# Podíváme se, kolik máme chybějících dat u pohlaví
table(teens$missing_gender)
teens$age <- ifelse(teens$age < 13 | teens$age > 19, NA, teens$age)
summary(teens$age)
teens$mean_age <- ave(teens$age, teens$gradyear, FUN=function(x) mean(x, na.rm=TRUE))
View(teens)
View(teens)
teens$age <- ifelse(is.na(teens$age), teens$mean_age, teens$age)
summary(teens$age)
set.seed(2345)
norm_data <- scale(teens[, 5:40]) # Normalizace příznaků
kmeans_result <- kmeans(norm_data, centers=5)
# Velikosti a středy shluků
print(kmeans_result$size)
print(kmeans_result$centers)
teens$cluster <- kmeans_result$cluster
# Průměrný věk, rozložení pohlaví a počet přátel
aggregate(cbind(age, friends) ~ cluster, data=teens, FUN=mean)
aggregate(gender ~ cluster, data=teens, FUN=function(x) table(x)/length(x))
View(kmeans_result)
View(kmeans_result)
library(ggplot2)
# PCA redukce na 2 rozměry
pca <- prcomp(norm_data)
pca_df <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2], cluster = factor(teens$cluster))
# Vykreslení pomocí ggplot2
ggplot(pca_df, aes(x = PC1, y = PC2, color = cluster)) +
geom_point(alpha = 0.6) +
labs(title = "2D PCA Vizualizace shluků", x = "Hlavní komponenta 1", y = "Hlavní komponenta 2") +
theme_minimal()
# Vykreslení pomocí ggplot2
ggplot(pca_df, aes(x = PC1, y = PC2, color = cluster)) +
geom_point(alpha = 0.6) +
labs(title = "2D PCA Vizualizace shluků", x = "Hlavní komponenta 1", y = "Hlavní komponenta 2") +
theme_minimal()
# Vykreslení pomocí ggplot2
ggplot(pca_df, aes(x = PC1, y = PC2, color = cluster)) +
geom_point(alpha = 0.6) +
labs(title = "2D PCA Vizualizace shluků", x = "Hlavní komponenta 1", y = "Hlavní komponenta 2") +
theme_minimal()
install.packages("class")
library(class)
# načtení iris dat
data(iris)
# rychlá explorace dat
dim(iris)
summary(iris)
set.seed(13579)
set.seed(13579)
shuffle <- sample(nrow(iris), nrow(iris), replace=F)
iris <- iris[shuffle,]
# vytvoření trénovací (50%), validační (30%) and testovací (20%) množiny
trainIris <- iris[1:(0.5*nrow(iris)),]
validIris <- iris[(0.5*nrow(iris) + 1):(0.8*nrow(iris)),]
testIris <- iris[(0.8*nrow(iris) + 1):(nrow(iris)),]
# ověření velikosti množin
dim(trainIris)
dim(validIris)
dim(testIris)
# alternativní způsob rozdělení dat
ind = sample(3,nrow(iris),replace=T,prob=c(0.5,0.3,0.2))
# vytvoření trénovací (50%), validační (30%) a testovací (20%) množiny
trainIris <- iris[ind == 1,]
validIris <- iris[ind == 2,]
testIris <- iris[ind == 3,]
# ověření velikosti množin
dim(trainIris)
dim(validIris)
dim(testIris)
# příprava hodnot parametru k
parameter <- seq(from = 1, to = 15, by = 2);
# příprava vektoru pro zaznamenávání hodnot klasifikační úspěšnosti
acc <- vector(length = length(parameter))
for (i in 1:length(parameter)) {
prediction <- knn(trainIris[,-5],validIris[,-5],cl = trainIris[,5],k =
parameter[i])
acc[i] <- sum(prediction == validIris[,5])/nrow(validIris)
}
# nalezení nejlepší hodnoty k podle validační množiny
kValidated <- parameter[which.max(acc)]
acc
# odhad úspěšnosti klasifikace na testovací množině
trainFull <- rbind(trainIris, validIris)
prediction <- knn(trainFull[,-5],testIris[,-5],cl = trainFull[,5],k =
kValidated)
testAcc <- sum(prediction == testIris[,5])/nrow(testIris)
install.packages("caret")
library(caret)
# reference by měly být skutečné třídy testovací množiny
reference <- factor(testIris[,5], levels = unique(testIris[,5]))
# Vytvoření confusion matrix
cm <- confusionMatrix(as.factor(prediction), reference)
print(cm)
## ROC
# PŘÍPRAVA DAT
# rozdeleni dat na trenovaci a testovaci mnozinu
set.seed(123)
training.samples <-  sample(2,nrow(pima.data),replace=T,prob=c(0.8,0.2))
## ROC
# PŘÍPRAVA DAT
# rozdeleni dat na trenovaci a testovaci mnozinu
data("PimaIndiansDiabetes2", package = "mlbench")
install.packages("mlbench")
## ROC
# PŘÍPRAVA DAT
# rozdeleni dat na trenovaci a testovaci mnozinu
library(mlbench)
data(PimaIndiansDiabetes2)
pima.data <- na.omit(PimaIndiansDiabetes2)
summary(pima.data)
set.seed(123)
training.samples <-  sample(2,nrow(pima.data),replace=T,prob=c(0.8,0.2))
train.data  <- pima.data[training.samples==1, ]
test.data <- pima.data[training.samples==2, ]
dim(train.data)
dim(test.data)
# VYTVOŘENÍ MODELU
model <- glm(diabetes ~.,family=binomial(link='logit'),data=train.data)
summary(model)
# celkova presnost
# Make predictions on the test data
fitted.results <- predict(model, test.data, type="response")
fitted.results <- ifelse(fitted.results > 0.5,"pos","neg")
fitted.results <- factor(fitted.results, levels=c("neg","pos"))
observed.classes <- test.data$diabetes
accuracy <- sum(fitted.results == observed.classes)/nrow(test.data)
accuracy
error <- sum(fitted.results != observed.classes)/nrow(test.data)
error
confusionMatrix(fitted.results, observed.classes, pos="pos")
library(ROCR)
install.packages("ROCR")
library(ROCR)
prob <- predict(model, test.data, type="response")
pr <- prediction(prob, test.data$diabetes)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf, main="ROC krivka")
points(x = 0, y = 1, pch=15, col="red", cex=2)
points(x = 0.1064, y=0.6667, pch=19, col="blue", cex=2)
# krab� data - data integrovan� v R
install.packages("MASS")
# krab� data - data integrovan� v R
install.packages("MASS")
library(MASS)
library(rpart)
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
data(crabs)
# nastavit gener�tor n�hodn�ch c�sel
set.seed(12345)
# vytvoren� tr�novac� mnoziny (80%), kter� bude rozdelena na 10 slozek, a testovac� mnoziny (20%)
ind <- sample(1:nrow(crabs),0.8*nrow(crabs))
trainCrabs <- crabs[ind,]
testCrabs <- crabs[-ind,]
# toto je funkce
drawLearningCurve <- function(x, y, xtest, ytest, nfolds=10) {
folds <- rep_len(1:nfolds,nrow(x))
acc <- vector(length=nfolds)
for(j in 1:nfolds){
train <- cbind(y[folds <= j],x[folds <= j,])
names(train)[1] <- 'class'
tree <- rpart(class ~ .,data=train,control = rpart.control(minsplit = 3))
acc[j] = sum(predict(tree,newdata=xtest,type='class') == ytest)/length(ytest)
}
plot((1:nfolds)/nfolds,acc,type="b",col=2,xlab='Mohutnost mnoziny',ylab='Uspesnost',ylim=c(0,1))
abline(h=0.5, col="black")
}
# an example of use
drawLearningCurve(trainCrabs[,-1],trainCrabs[,1],testCrabs[,-1],testCrabs[,1],20)
# nacten� krab�ch dat
library(MASS)
library(rpart)
library(rpart.plot)
data(crabs)
# nastavit gener�tor n�hodn�ch c�sel
set.seed(12345)
# vytvoren� tr�novac� mnoziny (80%), kter� bude rozdelena na 10 slozek, a testovac� mnoziny (20%)
ind <- sample(1:nrow(crabs),0.8*nrow(crabs))
trainCrabs <- crabs[ind,]
testCrabs <- crabs[-ind,]
folds <- rep_len(1:10,nrow(trainCrabs))
# training set
dim(trainCrabs)
# folds in training set
table(folds)
# testing set
dim(testCrabs)
# hodnoty parametru maxdepth, kter� budeme optimalizovat
parameter <- seq(from = 1, to = 10, by = 1);
# inicializace vektoru pro klasifikacn� presnosti
accValid <- matrix(NA,nrow=length(parameter),ncol=10)
accTrain <- matrix(NA,nrow=length(parameter),ncol=10)
for (i in 1:length(parameter)){
for(j in 1:10){
train <- trainCrabs[folds!=j,]
valid <- trainCrabs[folds==j,]
tree <- rpart(sp ~ .,data=train,control = rpart.control(minsplit=10,maxdepth=parameter[i]))
accTrain[i,j] <- sum(predict(tree,type='class') == train$sp)/nrow(train)
accValid[i,j] <- sum(predict(tree,newdata=valid,type='class') == valid$sp)/nrow(valid)
}
}
avgAccTrain <- apply(accTrain,1,mean)
avgAccValid <- apply(accValid,1,mean)
# z�vislost tr�novac� (zelen�) a validacn� (cerven�) �spesnosti
plot(parameter,avgAccValid,type="b",col=2,xlab='Maximal tree depth',ylab='Accuracy',ylim=c(0.5,1))
lines(parameter,avgAccTrain,type="b",col=3)
legend('bottomright',c('Validation set','Training set'),col=c(2,3),pch='---')
# nalezen� optim�ln� hodnoty parametru z hlediska �spesnosti klasifikace
maxdepthValidated = parameter[which.max(avgAccValid)]
# odhad �spesnosti klasifikace na nez�visl�ch datech
finalTree <- rpart(sp ~ .,data=trainCrabs,control = rpart.control(minsplit=10,maxdepth=maxdepthValidated))
testAcc <- sum(predict(finalTree,newdata=testCrabs,type='class') == testCrabs$sp)/nrow(testCrabs)
# v�sledn� rozhodovac� strom
rpart.plot(finalTree)
library(MASS)
library(rpart)
library(rpart.plot)
data(crabs)
# nastavení generátoru náhodných čísel pro reprodukovatelnost
set.seed(12345)
# nahrání celých dat jako základ pro bootstrap
allData <- crabs
# parametry
parameter <- seq(from = 1, to = 10, by = 1)
numBootstraps <- 32
# inicializace matice pro průměrné přesnosti
bootAcc <- matrix(NA, nrow = length(parameter), ncol = numBootstraps)
for (i in 1:length(parameter)) {
for (b in 1:numBootstraps) {
# výběr s návratem pro trénovací množinu
trainIndices <- sample(1:nrow(allData), size = nrow(allData), replace = TRUE)
testIndices <- setdiff(1:nrow(allData), trainIndices)
trainData <- allData[trainIndices,]
testData <- allData[testIndices,]
# vytvoření rozhodovacího stromu
tree <- rpart(sp ~ ., data = trainData, control = rpart.control(minsplit = 10, maxdepth = parameter[i]))
# výpočet přesnosti na testovací množině
preds <- predict(tree, newdata = testData, type = "class")
bootAcc[i, b] <- sum(preds == testData$sp) / nrow(testData)
}
}
# průměrná přesnost pro každou hloubku stromu
avgBootAcc <- rowMeans(bootAcc)
# graf zobrazující závislost průměrné přesnosti na hloubce stromu
plot(parameter, avgBootAcc, type = "b", col = 2, xlab = "Maximal tree depth", ylab = "Average Accuracy", ylim = c(0.5, 1))
legend("bottomright", "Bootstrap validation accuracy", col = 2, pch = 16)
# nacten� krab�ch dat
library(MASS)
library(rpart)
library(rpart.plot)
data(crabs)
# nastavit gener�tor n�hodn�ch c�sel
set.seed(12345)
# nacten� krab�ch dat
library(MASS)
library(rpart)
library(rpart.plot)
data(crabs)
# nastavit gener�tor n�hodn�ch c�sel
set.seed(12345)
# parametry
parameter <- seq(from = 1, to = 10, by = 1)
numBootstraps <- 32
numFolds <- 10
# nahrání celých dat jako základ pro bootstrap
allData <- crabs
# inicializace matice pro průměrné přesnosti
bootAcc <- matrix(NA, nrow = length(parameter), ncol = numBootstraps)
kfoldAcc <- matrix(NA, nrow = length(parameter), ncol = numFolds)
# Křížová validace
folds <- sample(rep(1:numFolds, length.out = nrow(allData)))
for (i in 1:length(parameter)) {
for (j in 1:numFolds) {
trainData <- allData[folds != j,]
testData <- allData[folds == j,]
treeKFold <- rpart(sp ~ ., data = trainData, control = rpart.control(minsplit = 10, maxdepth = parameter[i]))
predsKFold <- predict(treeKFold, newdata = testData, type = "class")
kfoldAcc[i, j] <- sum(predsKFold == testData$sp) / nrow(testData)
}
}
# Bootstrapping
for (i in 1:length(parameter)) {
for (b in 1:numBootstraps) {
trainIndices <- sample(1:nrow(allData), size = nrow(allData), replace = TRUE)
testIndices <- setdiff(1:nrow(allData), trainIndices)
trainData <- allData[trainIndices,]
testData <- allData[testIndices,]
treeBootstrap <- rpart(sp ~ ., data = trainData, control = rpart.control(minsplit = 10, maxdepth = parameter[i]))
predsBootstrap <- predict(treeBootstrap, newdata = testData, type = "class")
bootAcc[i, b] <- sum(predsBootstrap == testData$sp) / nrow(testData)
}
}
avgKfoldAcc <- apply(kfoldAcc, 1, mean)
avgBootAcc <- rowMeans(bootAcc)
# Výsledky porovnání
plot(parameter, avgKfoldAcc, type = "b", pch = 19, col = "blue", ylim = c(0.5, 1), ylab = "Accuracy", xlab = "Max Depth")
points(parameter, avgBootAcc, type = "b", pch = 17, col = "red")
legend("bottomright", legend = c("10-Fold Cross Validation", "Bootstrapping"), col = c("blue", "red"), pch = c(19, 17))
View(bootAcc)
View(bootAcc)
parameter <- seq(from = 1, to = 100, by = 1)
numBootstraps <- 32
numFolds <- 10
allData <- crabs
bootAcc <- matrix(NA, nrow = length(parameter), ncol = numBootstraps)
kfoldAcc <- matrix(NA, nrow = length(parameter), ncol = numFolds)
# Křížová validace
folds <- sample(rep(1:numFolds, length.out = nrow(allData)))
for (i in 1:length(parameter)) {
for (j in 1:numFolds) {
trainData <- allData[folds != j,]
testData <- allData[folds == j,]
treeKFold <- rpart(sp ~ ., data = trainData, control = rpart.control(minsplit = 10, maxdepth = parameter[i]))
predsKFold <- predict(treeKFold, newdata = testData, type = "class")
kfoldAcc[i, j] <- sum(predsKFold == testData$sp) / nrow(testData)
}
}
parameter <- seq(from = 1, to = 30, by = 1)
numBootstraps <- 32
numFolds <- 10
allData <- crabs
bootAcc <- matrix(NA, nrow = length(parameter), ncol = numBootstraps)
kfoldAcc <- matrix(NA, nrow = length(parameter), ncol = numFolds)
# Křížová validace
folds <- sample(rep(1:numFolds, length.out = nrow(allData)))
for (i in 1:length(parameter)) {
for (j in 1:numFolds) {
trainData <- allData[folds != j,]
testData <- allData[folds == j,]
treeKFold <- rpart(sp ~ ., data = trainData, control = rpart.control(minsplit = 10, maxdepth = parameter[i]))
predsKFold <- predict(treeKFold, newdata = testData, type = "class")
kfoldAcc[i, j] <- sum(predsKFold == testData$sp) / nrow(testData)
}
}
# Bootstrapping
for (i in 1:length(parameter)) {
for (b in 1:numBootstraps) {
trainIndices <- sample(1:nrow(allData), size = nrow(allData), replace = TRUE)
testIndices <- setdiff(1:nrow(allData), trainIndices)
trainData <- allData[trainIndices,]
testData <- allData[testIndices,]
treeBootstrap <- rpart(sp ~ ., data = trainData, control = rpart.control(minsplit = 10, maxdepth = parameter[i]))
predsBootstrap <- predict(treeBootstrap, newdata = testData, type = "class")
bootAcc[i, b] <- sum(predsBootstrap == testData$sp) / nrow(testData)
}
}
avgKfoldAcc <- apply(kfoldAcc, 1, mean)
avgBootAcc <- rowMeans(bootAcc)
plot(parameter, avgKfoldAcc, type = "b", pch = 19, col = "blue", ylim = c(0.5, 1), ylab = "Accuracy", xlab = "Max Depth")
points(parameter, avgBootAcc, type = "b", pch = 17, col = "red")
legend("bottomright", legend = c("10-Fold Cross Validation", "Bootstrapping"), col = c("blue", "red"), pch = c(19, 17))
library(MASS)
library(rpart)
library(rpart.plot)
data(crabs)
set.seed(12345)
parameter <- seq(from = 1, to = 10, by = 1)
numBootstraps <- 32
numFolds <- 10
allData <- crabs
bootAcc <- matrix(NA, nrow = length(parameter), ncol = numBootstraps)
kfoldAcc <- matrix(NA, nrow = length(parameter), ncol = numFolds)
# Křížová validace
folds <- sample(rep(1:numFolds, length.out = nrow(allData)))
for (i in 1:length(parameter)) {
for (j in 1:numFolds) {
trainData <- allData[folds != j,]
testData <- allData[folds == j,]
treeKFold <- rpart(sp ~ ., data = trainData, control = rpart.control(minsplit = 10, maxdepth = parameter[i]))
predsKFold <- predict(treeKFold, newdata = testData, type = "class")
kfoldAcc[i, j] <- sum(predsKFold == testData$sp) / nrow(testData)
}
}
# Bootstrapping
for (i in 1:length(parameter)) {
for (b in 1:numBootstraps) {
trainIndices <- sample(1:nrow(allData), size = nrow(allData), replace = TRUE)
testIndices <- setdiff(1:nrow(allData), trainIndices)
trainData <- allData[trainIndices,]
testData <- allData[testIndices,]
treeBootstrap <- rpart(sp ~ ., data = trainData, control = rpart.control(minsplit = 10, maxdepth = parameter[i]))
predsBootstrap <- predict(treeBootstrap, newdata = testData, type = "class")
bootAcc[i, b] <- sum(predsBootstrap == testData$sp) / nrow(testData)
}
}
avgKfoldAcc <- apply(kfoldAcc, 1, mean)
avgBootAcc <- rowMeans(bootAcc)
plot(parameter, avgKfoldAcc, type = "b", pch = 19, col = "blue", ylim = c(0.5, 1), ylab = "Accuracy", xlab = "Max Depth")
points(parameter, avgBootAcc, type = "b", pch = 17, col = "red")
legend("bottomright", legend = c("10-Fold Cross Validation", "Bootstrapping"), col = c("blue", "red"), pch = c(19, 17))
